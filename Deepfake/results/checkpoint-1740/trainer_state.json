{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1740,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017241379310344827,
      "grad_norm": 2.5936832427978516,
      "learning_rate": 4.971264367816092e-05,
      "loss": 0.6607,
      "step": 10
    },
    {
      "epoch": 0.034482758620689655,
      "grad_norm": 5.04218864440918,
      "learning_rate": 4.9425287356321845e-05,
      "loss": 0.4545,
      "step": 20
    },
    {
      "epoch": 0.05172413793103448,
      "grad_norm": 0.8874927163124084,
      "learning_rate": 4.913793103448276e-05,
      "loss": 0.1779,
      "step": 30
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 0.40262681245803833,
      "learning_rate": 4.885057471264368e-05,
      "loss": 0.0833,
      "step": 40
    },
    {
      "epoch": 0.08620689655172414,
      "grad_norm": 0.5579108595848083,
      "learning_rate": 4.85632183908046e-05,
      "loss": 0.0948,
      "step": 50
    },
    {
      "epoch": 0.10344827586206896,
      "grad_norm": 0.1585635393857956,
      "learning_rate": 4.827586206896552e-05,
      "loss": 0.0128,
      "step": 60
    },
    {
      "epoch": 0.1206896551724138,
      "grad_norm": 0.12149885296821594,
      "learning_rate": 4.798850574712644e-05,
      "loss": 0.0696,
      "step": 70
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 0.09655608981847763,
      "learning_rate": 4.770114942528736e-05,
      "loss": 0.0065,
      "step": 80
    },
    {
      "epoch": 0.15517241379310345,
      "grad_norm": 0.08148041367530823,
      "learning_rate": 4.741379310344828e-05,
      "loss": 0.0052,
      "step": 90
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 0.07030971348285675,
      "learning_rate": 4.7126436781609195e-05,
      "loss": 0.0041,
      "step": 100
    },
    {
      "epoch": 0.1896551724137931,
      "grad_norm": 0.05784648284316063,
      "learning_rate": 4.6839080459770116e-05,
      "loss": 0.0034,
      "step": 110
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 0.04742524400353432,
      "learning_rate": 4.655172413793104e-05,
      "loss": 0.0029,
      "step": 120
    },
    {
      "epoch": 0.22413793103448276,
      "grad_norm": 0.04222293198108673,
      "learning_rate": 4.626436781609196e-05,
      "loss": 0.0024,
      "step": 130
    },
    {
      "epoch": 0.2413793103448276,
      "grad_norm": 0.039586298167705536,
      "learning_rate": 4.597701149425287e-05,
      "loss": 0.0021,
      "step": 140
    },
    {
      "epoch": 0.25862068965517243,
      "grad_norm": 0.034121569246053696,
      "learning_rate": 4.5689655172413794e-05,
      "loss": 0.0018,
      "step": 150
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 0.031423550099134445,
      "learning_rate": 4.5402298850574716e-05,
      "loss": 0.0016,
      "step": 160
    },
    {
      "epoch": 0.29310344827586204,
      "grad_norm": 0.02912888117134571,
      "learning_rate": 4.511494252873563e-05,
      "loss": 0.0418,
      "step": 170
    },
    {
      "epoch": 0.3103448275862069,
      "grad_norm": 0.027829233556985855,
      "learning_rate": 4.482758620689655e-05,
      "loss": 0.0831,
      "step": 180
    },
    {
      "epoch": 0.3275862068965517,
      "grad_norm": 0.10419639199972153,
      "learning_rate": 4.454022988505747e-05,
      "loss": 0.2431,
      "step": 190
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 0.046179670840501785,
      "learning_rate": 4.4252873563218394e-05,
      "loss": 0.0024,
      "step": 200
    },
    {
      "epoch": 0.3620689655172414,
      "grad_norm": 0.03943876922130585,
      "learning_rate": 4.396551724137931e-05,
      "loss": 0.0729,
      "step": 210
    },
    {
      "epoch": 0.3793103448275862,
      "grad_norm": 0.05223412811756134,
      "learning_rate": 4.367816091954024e-05,
      "loss": 0.0806,
      "step": 220
    },
    {
      "epoch": 0.39655172413793105,
      "grad_norm": 0.041366685181856155,
      "learning_rate": 4.339080459770115e-05,
      "loss": 0.0023,
      "step": 230
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 0.03711611405014992,
      "learning_rate": 4.3103448275862066e-05,
      "loss": 0.0019,
      "step": 240
    },
    {
      "epoch": 0.43103448275862066,
      "grad_norm": 0.030888166278600693,
      "learning_rate": 4.2816091954022994e-05,
      "loss": 0.0016,
      "step": 250
    },
    {
      "epoch": 0.4482758620689655,
      "grad_norm": 0.027964089065790176,
      "learning_rate": 4.252873563218391e-05,
      "loss": 0.0015,
      "step": 260
    },
    {
      "epoch": 0.46551724137931033,
      "grad_norm": 0.025312568992376328,
      "learning_rate": 4.224137931034483e-05,
      "loss": 0.0013,
      "step": 270
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 0.02383635751903057,
      "learning_rate": 4.195402298850575e-05,
      "loss": 0.0012,
      "step": 280
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.021753674373030663,
      "learning_rate": 4.166666666666667e-05,
      "loss": 0.0011,
      "step": 290
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 0.019886162132024765,
      "learning_rate": 4.1379310344827587e-05,
      "loss": 0.001,
      "step": 300
    },
    {
      "epoch": 0.5344827586206896,
      "grad_norm": 0.018876325339078903,
      "learning_rate": 4.109195402298851e-05,
      "loss": 0.0009,
      "step": 310
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 0.017580321058630943,
      "learning_rate": 4.080459770114943e-05,
      "loss": 0.0008,
      "step": 320
    },
    {
      "epoch": 0.5689655172413793,
      "grad_norm": 0.015544956550002098,
      "learning_rate": 4.0517241379310344e-05,
      "loss": 0.0008,
      "step": 330
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 0.015221121720969677,
      "learning_rate": 4.0229885057471265e-05,
      "loss": 0.0007,
      "step": 340
    },
    {
      "epoch": 0.603448275862069,
      "grad_norm": 0.014960471540689468,
      "learning_rate": 3.9942528735632186e-05,
      "loss": 0.0007,
      "step": 350
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 0.013560828752815723,
      "learning_rate": 3.965517241379311e-05,
      "loss": 0.0006,
      "step": 360
    },
    {
      "epoch": 0.6379310344827587,
      "grad_norm": 0.013700570911169052,
      "learning_rate": 3.936781609195402e-05,
      "loss": 0.0006,
      "step": 370
    },
    {
      "epoch": 0.6551724137931034,
      "grad_norm": 0.011968374252319336,
      "learning_rate": 3.908045977011495e-05,
      "loss": 0.0006,
      "step": 380
    },
    {
      "epoch": 0.6724137931034483,
      "grad_norm": 0.011644795536994934,
      "learning_rate": 3.8793103448275865e-05,
      "loss": 0.0005,
      "step": 390
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 0.011345883831381798,
      "learning_rate": 3.850574712643678e-05,
      "loss": 0.0005,
      "step": 400
    },
    {
      "epoch": 0.7068965517241379,
      "grad_norm": 0.010393058881163597,
      "learning_rate": 3.82183908045977e-05,
      "loss": 0.0005,
      "step": 410
    },
    {
      "epoch": 0.7241379310344828,
      "grad_norm": 0.010386484675109386,
      "learning_rate": 3.793103448275862e-05,
      "loss": 0.0005,
      "step": 420
    },
    {
      "epoch": 0.7413793103448276,
      "grad_norm": 0.009744665585458279,
      "learning_rate": 3.764367816091954e-05,
      "loss": 0.0004,
      "step": 430
    },
    {
      "epoch": 0.7586206896551724,
      "grad_norm": 0.009590468369424343,
      "learning_rate": 3.735632183908046e-05,
      "loss": 0.0004,
      "step": 440
    },
    {
      "epoch": 0.7758620689655172,
      "grad_norm": 0.009154150262475014,
      "learning_rate": 3.7068965517241385e-05,
      "loss": 0.0004,
      "step": 450
    },
    {
      "epoch": 0.7931034482758621,
      "grad_norm": 0.008997919037938118,
      "learning_rate": 3.67816091954023e-05,
      "loss": 0.0004,
      "step": 460
    },
    {
      "epoch": 0.8103448275862069,
      "grad_norm": 0.008509515784680843,
      "learning_rate": 3.649425287356322e-05,
      "loss": 0.0004,
      "step": 470
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 0.008223678916692734,
      "learning_rate": 3.620689655172414e-05,
      "loss": 0.0004,
      "step": 480
    },
    {
      "epoch": 0.8448275862068966,
      "grad_norm": 0.00758435670286417,
      "learning_rate": 3.591954022988506e-05,
      "loss": 0.0003,
      "step": 490
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 0.0074744271114468575,
      "learning_rate": 3.563218390804598e-05,
      "loss": 0.0003,
      "step": 500
    },
    {
      "epoch": 0.8793103448275862,
      "grad_norm": 0.007454875390976667,
      "learning_rate": 3.53448275862069e-05,
      "loss": 0.0003,
      "step": 510
    },
    {
      "epoch": 0.896551724137931,
      "grad_norm": 0.007157924585044384,
      "learning_rate": 3.505747126436782e-05,
      "loss": 0.0003,
      "step": 520
    },
    {
      "epoch": 0.9137931034482759,
      "grad_norm": 0.006946589332073927,
      "learning_rate": 3.4770114942528735e-05,
      "loss": 0.0003,
      "step": 530
    },
    {
      "epoch": 0.9310344827586207,
      "grad_norm": 0.0067284563556313515,
      "learning_rate": 3.4482758620689657e-05,
      "loss": 0.0003,
      "step": 540
    },
    {
      "epoch": 0.9482758620689655,
      "grad_norm": 0.00652291439473629,
      "learning_rate": 3.419540229885058e-05,
      "loss": 0.0003,
      "step": 550
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 0.006468599662184715,
      "learning_rate": 3.390804597701149e-05,
      "loss": 0.0003,
      "step": 560
    },
    {
      "epoch": 0.9827586206896551,
      "grad_norm": 0.0061700050719082355,
      "learning_rate": 3.3620689655172414e-05,
      "loss": 0.0003,
      "step": 570
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.005980886053293943,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 0.0002,
      "step": 580
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.00017967642634175718,
      "eval_runtime": 566.6055,
      "eval_samples_per_second": 8.179,
      "eval_steps_per_second": 1.024,
      "step": 580
    },
    {
      "epoch": 1.0172413793103448,
      "grad_norm": 0.005443067755550146,
      "learning_rate": 3.3045977011494256e-05,
      "loss": 0.0002,
      "step": 590
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 0.005919346585869789,
      "learning_rate": 3.275862068965517e-05,
      "loss": 0.0002,
      "step": 600
    },
    {
      "epoch": 1.0517241379310345,
      "grad_norm": 0.00538916140794754,
      "learning_rate": 3.24712643678161e-05,
      "loss": 0.0002,
      "step": 610
    },
    {
      "epoch": 1.0689655172413792,
      "grad_norm": 0.00514333276078105,
      "learning_rate": 3.218390804597701e-05,
      "loss": 0.0002,
      "step": 620
    },
    {
      "epoch": 1.0862068965517242,
      "grad_norm": 0.005011783912777901,
      "learning_rate": 3.1896551724137935e-05,
      "loss": 0.0002,
      "step": 630
    },
    {
      "epoch": 1.103448275862069,
      "grad_norm": 0.005112846381962299,
      "learning_rate": 3.160919540229885e-05,
      "loss": 0.0002,
      "step": 640
    },
    {
      "epoch": 1.1206896551724137,
      "grad_norm": 0.004895139951258898,
      "learning_rate": 3.132183908045977e-05,
      "loss": 0.0002,
      "step": 650
    },
    {
      "epoch": 1.1379310344827587,
      "grad_norm": 0.004565018694847822,
      "learning_rate": 3.103448275862069e-05,
      "loss": 0.0002,
      "step": 660
    },
    {
      "epoch": 1.1551724137931034,
      "grad_norm": 0.00477330107241869,
      "learning_rate": 3.0747126436781606e-05,
      "loss": 0.0002,
      "step": 670
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 0.004563583992421627,
      "learning_rate": 3.045977011494253e-05,
      "loss": 0.0002,
      "step": 680
    },
    {
      "epoch": 1.1896551724137931,
      "grad_norm": 0.004568100906908512,
      "learning_rate": 3.017241379310345e-05,
      "loss": 0.0002,
      "step": 690
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 0.0046887630596756935,
      "learning_rate": 2.988505747126437e-05,
      "loss": 0.0002,
      "step": 700
    },
    {
      "epoch": 1.2241379310344827,
      "grad_norm": 0.004261981230229139,
      "learning_rate": 2.9597701149425288e-05,
      "loss": 0.0002,
      "step": 710
    },
    {
      "epoch": 1.2413793103448276,
      "grad_norm": 0.004290647804737091,
      "learning_rate": 2.9310344827586206e-05,
      "loss": 0.0002,
      "step": 720
    },
    {
      "epoch": 1.2586206896551724,
      "grad_norm": 0.004188802093267441,
      "learning_rate": 2.9022988505747127e-05,
      "loss": 0.0002,
      "step": 730
    },
    {
      "epoch": 1.2758620689655173,
      "grad_norm": 0.003917949739843607,
      "learning_rate": 2.8735632183908045e-05,
      "loss": 0.0002,
      "step": 740
    },
    {
      "epoch": 1.293103448275862,
      "grad_norm": 0.003940439783036709,
      "learning_rate": 2.844827586206897e-05,
      "loss": 0.0002,
      "step": 750
    },
    {
      "epoch": 1.3103448275862069,
      "grad_norm": 0.004128696396946907,
      "learning_rate": 2.8160919540229884e-05,
      "loss": 0.0002,
      "step": 760
    },
    {
      "epoch": 1.3275862068965516,
      "grad_norm": 0.004070794675499201,
      "learning_rate": 2.787356321839081e-05,
      "loss": 0.0002,
      "step": 770
    },
    {
      "epoch": 1.3448275862068966,
      "grad_norm": 0.0037206218112260103,
      "learning_rate": 2.7586206896551727e-05,
      "loss": 0.0002,
      "step": 780
    },
    {
      "epoch": 1.3620689655172413,
      "grad_norm": 0.00400934973731637,
      "learning_rate": 2.7298850574712648e-05,
      "loss": 0.0001,
      "step": 790
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 0.0037558332551270723,
      "learning_rate": 2.7011494252873566e-05,
      "loss": 0.0001,
      "step": 800
    },
    {
      "epoch": 1.396551724137931,
      "grad_norm": 0.0035916264168918133,
      "learning_rate": 2.672413793103448e-05,
      "loss": 0.0001,
      "step": 810
    },
    {
      "epoch": 1.4137931034482758,
      "grad_norm": 0.003707454539835453,
      "learning_rate": 2.6436781609195405e-05,
      "loss": 0.0001,
      "step": 820
    },
    {
      "epoch": 1.4310344827586206,
      "grad_norm": 0.0034801277797669172,
      "learning_rate": 2.6149425287356323e-05,
      "loss": 0.0001,
      "step": 830
    },
    {
      "epoch": 1.4482758620689655,
      "grad_norm": 0.003501839004456997,
      "learning_rate": 2.5862068965517244e-05,
      "loss": 0.0001,
      "step": 840
    },
    {
      "epoch": 1.4655172413793103,
      "grad_norm": 0.003458078484982252,
      "learning_rate": 2.5574712643678162e-05,
      "loss": 0.0001,
      "step": 850
    },
    {
      "epoch": 1.4827586206896552,
      "grad_norm": 0.0031666585709899664,
      "learning_rate": 2.5287356321839083e-05,
      "loss": 0.0001,
      "step": 860
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.0033736126497387886,
      "learning_rate": 2.5e-05,
      "loss": 0.0001,
      "step": 870
    },
    {
      "epoch": 1.5172413793103448,
      "grad_norm": 0.003289664164185524,
      "learning_rate": 2.4712643678160922e-05,
      "loss": 0.0001,
      "step": 880
    },
    {
      "epoch": 1.5344827586206895,
      "grad_norm": 0.0031710772309452295,
      "learning_rate": 2.442528735632184e-05,
      "loss": 0.0001,
      "step": 890
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 0.0029777924064546824,
      "learning_rate": 2.413793103448276e-05,
      "loss": 0.0001,
      "step": 900
    },
    {
      "epoch": 1.5689655172413794,
      "grad_norm": 0.003144340356811881,
      "learning_rate": 2.385057471264368e-05,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 1.5862068965517242,
      "grad_norm": 0.0029524925630539656,
      "learning_rate": 2.3563218390804597e-05,
      "loss": 0.0001,
      "step": 920
    },
    {
      "epoch": 1.603448275862069,
      "grad_norm": 0.002912016585469246,
      "learning_rate": 2.327586206896552e-05,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 1.6206896551724137,
      "grad_norm": 0.002869528019800782,
      "learning_rate": 2.2988505747126437e-05,
      "loss": 0.0001,
      "step": 940
    },
    {
      "epoch": 1.6379310344827587,
      "grad_norm": 0.002966447500512004,
      "learning_rate": 2.2701149425287358e-05,
      "loss": 0.0001,
      "step": 950
    },
    {
      "epoch": 1.6551724137931034,
      "grad_norm": 0.0027959959115833044,
      "learning_rate": 2.2413793103448276e-05,
      "loss": 0.0001,
      "step": 960
    },
    {
      "epoch": 1.6724137931034484,
      "grad_norm": 0.0030403095297515392,
      "learning_rate": 2.2126436781609197e-05,
      "loss": 0.0001,
      "step": 970
    },
    {
      "epoch": 1.6896551724137931,
      "grad_norm": 0.0026587999891489744,
      "learning_rate": 2.183908045977012e-05,
      "loss": 0.0001,
      "step": 980
    },
    {
      "epoch": 1.706896551724138,
      "grad_norm": 0.002689346671104431,
      "learning_rate": 2.1551724137931033e-05,
      "loss": 0.0001,
      "step": 990
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 0.002710141707211733,
      "learning_rate": 2.1264367816091954e-05,
      "loss": 0.0001,
      "step": 1000
    },
    {
      "epoch": 1.7413793103448276,
      "grad_norm": 0.002674366347491741,
      "learning_rate": 2.0977011494252875e-05,
      "loss": 0.0001,
      "step": 1010
    },
    {
      "epoch": 1.7586206896551724,
      "grad_norm": 0.0026578502729535103,
      "learning_rate": 2.0689655172413793e-05,
      "loss": 0.0001,
      "step": 1020
    },
    {
      "epoch": 1.7758620689655173,
      "grad_norm": 0.00243232655338943,
      "learning_rate": 2.0402298850574715e-05,
      "loss": 0.0001,
      "step": 1030
    },
    {
      "epoch": 1.793103448275862,
      "grad_norm": 0.0025773164816200733,
      "learning_rate": 2.0114942528735632e-05,
      "loss": 0.0001,
      "step": 1040
    },
    {
      "epoch": 1.8103448275862069,
      "grad_norm": 0.0024439615663141012,
      "learning_rate": 1.9827586206896554e-05,
      "loss": 0.0001,
      "step": 1050
    },
    {
      "epoch": 1.8275862068965516,
      "grad_norm": 0.0024733347818255424,
      "learning_rate": 1.9540229885057475e-05,
      "loss": 0.0001,
      "step": 1060
    },
    {
      "epoch": 1.8448275862068966,
      "grad_norm": 0.002439699834212661,
      "learning_rate": 1.925287356321839e-05,
      "loss": 0.0001,
      "step": 1070
    },
    {
      "epoch": 1.8620689655172413,
      "grad_norm": 0.0025980097707360983,
      "learning_rate": 1.896551724137931e-05,
      "loss": 0.0001,
      "step": 1080
    },
    {
      "epoch": 1.8793103448275863,
      "grad_norm": 0.002387199318036437,
      "learning_rate": 1.867816091954023e-05,
      "loss": 0.0001,
      "step": 1090
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 0.0023106117732822895,
      "learning_rate": 1.839080459770115e-05,
      "loss": 0.0001,
      "step": 1100
    },
    {
      "epoch": 1.9137931034482758,
      "grad_norm": 0.0023344189394265413,
      "learning_rate": 1.810344827586207e-05,
      "loss": 0.0001,
      "step": 1110
    },
    {
      "epoch": 1.9310344827586206,
      "grad_norm": 0.0023740960750728846,
      "learning_rate": 1.781609195402299e-05,
      "loss": 0.0001,
      "step": 1120
    },
    {
      "epoch": 1.9482758620689655,
      "grad_norm": 0.002346088644117117,
      "learning_rate": 1.752873563218391e-05,
      "loss": 0.0001,
      "step": 1130
    },
    {
      "epoch": 1.9655172413793105,
      "grad_norm": 0.002391340211033821,
      "learning_rate": 1.7241379310344828e-05,
      "loss": 0.0001,
      "step": 1140
    },
    {
      "epoch": 1.9827586206896552,
      "grad_norm": 0.002250733319669962,
      "learning_rate": 1.6954022988505746e-05,
      "loss": 0.0001,
      "step": 1150
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.002164299599826336,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0001,
      "step": 1160
    },
    {
      "epoch": 2.0,
      "eval_loss": 6.0841484810225666e-05,
      "eval_runtime": 581.8939,
      "eval_samples_per_second": 7.964,
      "eval_steps_per_second": 0.997,
      "step": 1160
    },
    {
      "epoch": 2.0172413793103448,
      "grad_norm": 0.0022026619408279657,
      "learning_rate": 1.6379310344827585e-05,
      "loss": 0.0001,
      "step": 1170
    },
    {
      "epoch": 2.0344827586206895,
      "grad_norm": 0.002242449903860688,
      "learning_rate": 1.6091954022988507e-05,
      "loss": 0.0001,
      "step": 1180
    },
    {
      "epoch": 2.0517241379310347,
      "grad_norm": 0.002464097458869219,
      "learning_rate": 1.5804597701149425e-05,
      "loss": 0.0001,
      "step": 1190
    },
    {
      "epoch": 2.0689655172413794,
      "grad_norm": 0.0022003022022545338,
      "learning_rate": 1.5517241379310346e-05,
      "loss": 0.0001,
      "step": 1200
    },
    {
      "epoch": 2.086206896551724,
      "grad_norm": 0.0021785416174679995,
      "learning_rate": 1.5229885057471265e-05,
      "loss": 0.0001,
      "step": 1210
    },
    {
      "epoch": 2.103448275862069,
      "grad_norm": 0.0021638190373778343,
      "learning_rate": 1.4942528735632185e-05,
      "loss": 0.0001,
      "step": 1220
    },
    {
      "epoch": 2.1206896551724137,
      "grad_norm": 0.0022439502645283937,
      "learning_rate": 1.4655172413793103e-05,
      "loss": 0.0001,
      "step": 1230
    },
    {
      "epoch": 2.1379310344827585,
      "grad_norm": 0.0020717435982078314,
      "learning_rate": 1.4367816091954022e-05,
      "loss": 0.0001,
      "step": 1240
    },
    {
      "epoch": 2.1551724137931036,
      "grad_norm": 0.0020531516056507826,
      "learning_rate": 1.4080459770114942e-05,
      "loss": 0.0001,
      "step": 1250
    },
    {
      "epoch": 2.1724137931034484,
      "grad_norm": 0.0019899189937859774,
      "learning_rate": 1.3793103448275863e-05,
      "loss": 0.0001,
      "step": 1260
    },
    {
      "epoch": 2.189655172413793,
      "grad_norm": 0.0020303332712501287,
      "learning_rate": 1.3505747126436783e-05,
      "loss": 0.0001,
      "step": 1270
    },
    {
      "epoch": 2.206896551724138,
      "grad_norm": 0.0021102086175233126,
      "learning_rate": 1.3218390804597702e-05,
      "loss": 0.0001,
      "step": 1280
    },
    {
      "epoch": 2.2241379310344827,
      "grad_norm": 0.0019932142458856106,
      "learning_rate": 1.2931034482758622e-05,
      "loss": 0.0001,
      "step": 1290
    },
    {
      "epoch": 2.2413793103448274,
      "grad_norm": 0.002080111298710108,
      "learning_rate": 1.2643678160919542e-05,
      "loss": 0.0001,
      "step": 1300
    },
    {
      "epoch": 2.2586206896551726,
      "grad_norm": 0.0020179597195237875,
      "learning_rate": 1.2356321839080461e-05,
      "loss": 0.0001,
      "step": 1310
    },
    {
      "epoch": 2.2758620689655173,
      "grad_norm": 0.0019549003336578608,
      "learning_rate": 1.206896551724138e-05,
      "loss": 0.0001,
      "step": 1320
    },
    {
      "epoch": 2.293103448275862,
      "grad_norm": 0.0020865327678620815,
      "learning_rate": 1.1781609195402299e-05,
      "loss": 0.0001,
      "step": 1330
    },
    {
      "epoch": 2.310344827586207,
      "grad_norm": 0.0018828624160960317,
      "learning_rate": 1.1494252873563218e-05,
      "loss": 0.0001,
      "step": 1340
    },
    {
      "epoch": 2.3275862068965516,
      "grad_norm": 0.0018662698566913605,
      "learning_rate": 1.1206896551724138e-05,
      "loss": 0.0001,
      "step": 1350
    },
    {
      "epoch": 2.344827586206897,
      "grad_norm": 0.001857285387814045,
      "learning_rate": 1.091954022988506e-05,
      "loss": 0.0001,
      "step": 1360
    },
    {
      "epoch": 2.3620689655172415,
      "grad_norm": 0.001844724640250206,
      "learning_rate": 1.0632183908045977e-05,
      "loss": 0.0001,
      "step": 1370
    },
    {
      "epoch": 2.3793103448275863,
      "grad_norm": 0.0017886353889480233,
      "learning_rate": 1.0344827586206897e-05,
      "loss": 0.0001,
      "step": 1380
    },
    {
      "epoch": 2.396551724137931,
      "grad_norm": 0.0019668207969516516,
      "learning_rate": 1.0057471264367816e-05,
      "loss": 0.0001,
      "step": 1390
    },
    {
      "epoch": 2.413793103448276,
      "grad_norm": 0.0018605877412483096,
      "learning_rate": 9.770114942528738e-06,
      "loss": 0.0001,
      "step": 1400
    },
    {
      "epoch": 2.4310344827586206,
      "grad_norm": 0.0018027386395260692,
      "learning_rate": 9.482758620689655e-06,
      "loss": 0.0001,
      "step": 1410
    },
    {
      "epoch": 2.4482758620689653,
      "grad_norm": 0.0018370413454249501,
      "learning_rate": 9.195402298850575e-06,
      "loss": 0.0001,
      "step": 1420
    },
    {
      "epoch": 2.4655172413793105,
      "grad_norm": 0.0019249517936259508,
      "learning_rate": 8.908045977011495e-06,
      "loss": 0.0001,
      "step": 1430
    },
    {
      "epoch": 2.4827586206896552,
      "grad_norm": 0.0019102703081443906,
      "learning_rate": 8.620689655172414e-06,
      "loss": 0.0001,
      "step": 1440
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.0019130830187350512,
      "learning_rate": 8.333333333333334e-06,
      "loss": 0.0001,
      "step": 1450
    },
    {
      "epoch": 2.5172413793103448,
      "grad_norm": 0.0019449306419119239,
      "learning_rate": 8.045977011494253e-06,
      "loss": 0.0001,
      "step": 1460
    },
    {
      "epoch": 2.5344827586206895,
      "grad_norm": 0.001796119031496346,
      "learning_rate": 7.758620689655173e-06,
      "loss": 0.0001,
      "step": 1470
    },
    {
      "epoch": 2.5517241379310347,
      "grad_norm": 0.0017440468072891235,
      "learning_rate": 7.4712643678160925e-06,
      "loss": 0.0001,
      "step": 1480
    },
    {
      "epoch": 2.5689655172413794,
      "grad_norm": 0.0017786856042221189,
      "learning_rate": 7.183908045977011e-06,
      "loss": 0.0001,
      "step": 1490
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 0.0018597355810925364,
      "learning_rate": 6.896551724137932e-06,
      "loss": 0.0001,
      "step": 1500
    },
    {
      "epoch": 2.603448275862069,
      "grad_norm": 0.0017648187931627035,
      "learning_rate": 6.609195402298851e-06,
      "loss": 0.0001,
      "step": 1510
    },
    {
      "epoch": 2.6206896551724137,
      "grad_norm": 0.0017601278377696872,
      "learning_rate": 6.321839080459771e-06,
      "loss": 0.0001,
      "step": 1520
    },
    {
      "epoch": 2.637931034482759,
      "grad_norm": 0.0017502185655757785,
      "learning_rate": 6.03448275862069e-06,
      "loss": 0.0001,
      "step": 1530
    },
    {
      "epoch": 2.655172413793103,
      "grad_norm": 0.001753892400301993,
      "learning_rate": 5.747126436781609e-06,
      "loss": 0.0001,
      "step": 1540
    },
    {
      "epoch": 2.6724137931034484,
      "grad_norm": 0.0016946644755080342,
      "learning_rate": 5.45977011494253e-06,
      "loss": 0.0001,
      "step": 1550
    },
    {
      "epoch": 2.689655172413793,
      "grad_norm": 0.001783599378541112,
      "learning_rate": 5.172413793103448e-06,
      "loss": 0.0001,
      "step": 1560
    },
    {
      "epoch": 2.706896551724138,
      "grad_norm": 0.0017759180627763271,
      "learning_rate": 4.885057471264369e-06,
      "loss": 0.0001,
      "step": 1570
    },
    {
      "epoch": 2.7241379310344827,
      "grad_norm": 0.0017218819120898843,
      "learning_rate": 4.5977011494252875e-06,
      "loss": 0.0001,
      "step": 1580
    },
    {
      "epoch": 2.7413793103448274,
      "grad_norm": 0.0016811942914500833,
      "learning_rate": 4.310344827586207e-06,
      "loss": 0.0001,
      "step": 1590
    },
    {
      "epoch": 2.7586206896551726,
      "grad_norm": 0.0017582618165761232,
      "learning_rate": 4.022988505747127e-06,
      "loss": 0.0001,
      "step": 1600
    },
    {
      "epoch": 2.7758620689655173,
      "grad_norm": 0.001848816522397101,
      "learning_rate": 3.7356321839080462e-06,
      "loss": 0.0001,
      "step": 1610
    },
    {
      "epoch": 2.793103448275862,
      "grad_norm": 0.0017523870337754488,
      "learning_rate": 3.448275862068966e-06,
      "loss": 0.0001,
      "step": 1620
    },
    {
      "epoch": 2.810344827586207,
      "grad_norm": 0.001707645715214312,
      "learning_rate": 3.1609195402298854e-06,
      "loss": 0.0001,
      "step": 1630
    },
    {
      "epoch": 2.8275862068965516,
      "grad_norm": 0.0017925987485796213,
      "learning_rate": 2.8735632183908046e-06,
      "loss": 0.0001,
      "step": 1640
    },
    {
      "epoch": 2.844827586206897,
      "grad_norm": 0.001785592525266111,
      "learning_rate": 2.586206896551724e-06,
      "loss": 0.0001,
      "step": 1650
    },
    {
      "epoch": 2.862068965517241,
      "grad_norm": 0.0017369745764881372,
      "learning_rate": 2.2988505747126437e-06,
      "loss": 0.0001,
      "step": 1660
    },
    {
      "epoch": 2.8793103448275863,
      "grad_norm": 0.0017363271908834577,
      "learning_rate": 2.0114942528735633e-06,
      "loss": 0.0001,
      "step": 1670
    },
    {
      "epoch": 2.896551724137931,
      "grad_norm": 0.0017762900097295642,
      "learning_rate": 1.724137931034483e-06,
      "loss": 0.0001,
      "step": 1680
    },
    {
      "epoch": 2.913793103448276,
      "grad_norm": 0.0017800360219553113,
      "learning_rate": 1.4367816091954023e-06,
      "loss": 0.0001,
      "step": 1690
    },
    {
      "epoch": 2.9310344827586206,
      "grad_norm": 0.0016894094878807664,
      "learning_rate": 1.1494252873563219e-06,
      "loss": 0.0001,
      "step": 1700
    },
    {
      "epoch": 2.9482758620689653,
      "grad_norm": 0.0016883889911696315,
      "learning_rate": 8.620689655172415e-07,
      "loss": 0.0001,
      "step": 1710
    },
    {
      "epoch": 2.9655172413793105,
      "grad_norm": 0.0017332383431494236,
      "learning_rate": 5.747126436781609e-07,
      "loss": 0.0001,
      "step": 1720
    },
    {
      "epoch": 2.9827586206896552,
      "grad_norm": 0.0018206291133537889,
      "learning_rate": 2.8735632183908047e-07,
      "loss": 0.0001,
      "step": 1730
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.0017392894951626658,
      "learning_rate": 0.0,
      "loss": 0.0001,
      "step": 1740
    },
    {
      "epoch": 3.0,
      "eval_loss": 4.472154250834137e-05,
      "eval_runtime": 541.083,
      "eval_samples_per_second": 8.564,
      "eval_steps_per_second": 1.072,
      "step": 1740
    }
  ],
  "logging_steps": 10,
  "max_steps": 1740,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5228134820702045e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
